{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Classifier on the *Salammb√¥* Dataset with PyTorch\n",
    "We use here the `CrossEntropyLoss` for a binary classification. We implement the binary case as a multiclass problem with two classes.\n",
    "\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to import some modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset\n",
    "We can read the data from a file with the svmlight format or directly create numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(\n",
    "    [[35680, 2217], [42514, 2761], [15162, 990], [35298, 2274],\n",
    "     [29800, 1865], [40255, 2606], [74532, 4805], [37464, 2396],\n",
    "     [31030, 1993], [24843, 1627], [36172, 2375], [39552, 2560],\n",
    "     [72545, 4597], [75352, 4871], [18031, 1119], [36961, 2503],\n",
    "     [43621, 2992], [15694, 1042], [36231, 2487], [29945, 2014],\n",
    "     [40588, 2805], [75255, 5062], [37709, 2643], [30899, 2126],\n",
    "     [25486, 1784], [37497, 2641], [40398, 2766], [74105, 5047],\n",
    "     [76725, 5312], [18317, 1215]\n",
    "     ])\n",
    "\n",
    "y = np.array(\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scaling the Data\n",
    "Scaling and normalizing are usually very significant with neural networks. We use sklean transformers. They consist of two main methods: `fit()` and `transform()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99807515, 0.06201605],\n",
       "       [0.99789783, 0.06480679],\n",
       "       [0.99787509, 0.06515607],\n",
       "       [0.99793128, 0.06428964]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer()\n",
    "X_norm = normalizer.fit_transform(X)\n",
    "X_norm[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.68336574, -1.7197772 ],\n",
       "       [ 0.57376529, -0.56145427],\n",
       "       [ 0.43143908, -0.41648279],\n",
       "       [ 0.78308579, -0.77610221]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X_norm)\n",
    "X_scaled[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating PyTorch Tensors\n",
    "PyTorch has its own implementation of matrices called tensors. They are more or less equivalent to NumPy arrays. With the `CrossEntropyLoss` $\\mathbf{y}$  is a vector of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.LongTensor(y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6834, -1.7198],\n",
       "        [ 0.5738, -0.5615],\n",
       "        [ 0.4314, -0.4165],\n",
       "        [ 0.7831, -0.7761],\n",
       "        [ 1.5095, -1.5348],\n",
       "        [ 0.6568, -0.6464],\n",
       "        [ 0.7646, -0.7571],\n",
       "        [ 0.9700, -0.9692],\n",
       "        [ 0.8610, -0.8564],\n",
       "        [ 0.3516, -0.3355],\n",
       "        [ 0.2834, -0.2665],\n",
       "        [ 0.6618, -0.6515],\n",
       "        [ 1.2025, -1.2115],\n",
       "        [ 0.6947, -0.6852],\n",
       "        [ 1.7127, -1.7511],\n",
       "        [-0.5712,  0.5835],\n",
       "        [-0.9400,  0.9424],\n",
       "        [-0.0189,  0.0371],\n",
       "        [-0.9622,  0.9639],\n",
       "        [-0.3768,  0.3925],\n",
       "        [-1.1617,  1.1560],\n",
       "        [-0.3802,  0.3957],\n",
       "        [-1.5856,  1.5599],\n",
       "        [-1.0314,  1.0306],\n",
       "        [-1.5463,  1.5228],\n",
       "        [-1.7352,  1.7012],\n",
       "        [-0.8880,  0.8921],\n",
       "        [-0.7341,  0.7426],\n",
       "        [-1.2155,  1.2076],\n",
       "        [ 0.0071,  0.0112]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = torch.Tensor(X_scaled)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set a seed to have reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a classifier equivalent to a logistic regression with two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a model with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 10)\n",
    "        self.fc2 = nn.Linear(10, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the model. To try the network with one hidden layer, set `complex` to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_scaled.shape[1]\n",
    "if not complex:\n",
    "    model = Model(input_dim)\n",
    "else:\n",
    "    model = Model2(input_dim)\n",
    "loss_fn = nn.CrossEntropyLoss()    # binary cross entropy loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Model\n",
    "We will show three methods: batch gradient descent, stochastic descent, and minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the whole dataset (batch gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()               # sets PyTorch in the train mode\n",
    "for epoch in range(100):\n",
    "    Y_pred = model(X_scaled)\n",
    "    loss = loss_fn(Y_pred, Y)\n",
    "    optimizer.zero_grad()   # resets the gradients\n",
    "    loss.backward()         # gradient backpropagation\n",
    "    optimizer.step()        # weight updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, we fit the model with a batch size of one item (stochastic gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(50):\n",
    "    for x_scaled, y in zip(X_scaled, Y):\n",
    "        y_pred = model(x_scaled)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we fit it with mini-batches, first with a simple inner loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    # Would need to shuffle X and y\n",
    "    for i in range(0, X_scaled.size()[0], batch_size):\n",
    "        Y_batch_pred = model(X_scaled[i:i + batch_size])\n",
    "        loss = loss_fn(Y_batch_pred, Y[i:i + batch_size])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then with a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(X_scaled, Y)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(50):\n",
    "    for X_scaled_batch, Y_batch in dataloader:\n",
    "        Y_batch_pred = model(X_scaled_batch)\n",
    "        loss = loss_fn(Y_batch_pred, Y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.3396,  0.4205],\n",
       "         [ 0.1931, -0.5328],\n",
       "         [ 0.0524,  0.2045],\n",
       "         [ 0.5766, -0.4635],\n",
       "         [-0.3821,  1.0696],\n",
       "         [-0.2679,  0.1251],\n",
       "         [-0.6548,  0.7661],\n",
       "         [ 0.3985, -0.4925],\n",
       "         [ 1.1248, -0.9981],\n",
       "         [ 0.4658, -0.1773]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2447,  0.2726, -0.2628,  0.4770,  0.6425, -0.4957,  0.7729, -0.3846,\n",
       "          0.1056,  0.2783], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0772,  0.4339, -0.2504,  0.6221, -0.5545,  0.1489, -1.0388, -0.0928,\n",
       "           0.8791,  0.3127],\n",
       "         [ 0.3546, -0.2893, -0.1068, -0.3945,  1.0181,  0.2261,  0.6665, -0.2697,\n",
       "          -0.8445, -0.4070]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0949,  0.0394], requires_grad=True)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also in the form of a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-0.3396,  0.4205],\n",
       "                      [ 0.1931, -0.5328],\n",
       "                      [ 0.0524,  0.2045],\n",
       "                      [ 0.5766, -0.4635],\n",
       "                      [-0.3821,  1.0696],\n",
       "                      [-0.2679,  0.1251],\n",
       "                      [-0.6548,  0.7661],\n",
       "                      [ 0.3985, -0.4925],\n",
       "                      [ 1.1248, -0.9981],\n",
       "                      [ 0.4658, -0.1773]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.2447,  0.2726, -0.2628,  0.4770,  0.6425, -0.4957,  0.7729, -0.3846,\n",
       "                       0.1056,  0.2783])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0772,  0.4339, -0.2504,  0.6221, -0.5545,  0.1489, -1.0388, -0.0928,\n",
       "                        0.8791,  0.3127],\n",
       "                      [ 0.3546, -0.2893, -0.1068, -0.3945,  1.0181,  0.2261,  0.6665, -0.2697,\n",
       "                       -0.8445, -0.4070]])),\n",
       "             ('fc2.bias', tensor([-0.0949,  0.0394]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "### Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the probabilities to belong to class 1 for all the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.5468, -5.2841],\n",
       "        [ 2.2089, -1.9820],\n",
       "        [ 1.5893, -1.4184],\n",
       "        [ 2.8332, -2.5995]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred_proba = model(X_scaled)\n",
    "y_pred_proba[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recompute it with matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_params = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9961, 0.0050],\n",
      "        [0.9011, 0.1211],\n",
      "        [0.8305, 0.1949],\n",
      "        [0.9444, 0.0692]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "if complex:\n",
    "    print(torch.sigmoid(torch.relu(X_scaled @ m_params[0].T + m_params[1]) @ m_params[2].T + m_params[3])[:4])\n",
    "else:\n",
    "    print(torch.sigmoid(X_scaled @ m_params[0].T + m_params[1])[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = torch.argmax(y_pred_proba, dim=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We computed the accuracy from the training set. This is not a good practice. We should use a dedicated test set instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
