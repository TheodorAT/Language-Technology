{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14e3eabd450>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(array1, array2):\n",
    "        dot_product = np.dot(array1, array2)\n",
    "        cosine_similarity = dot_product/(np.linalg.norm(array1)*np.linalg.norm(array2))\n",
    "        return cosine_similarity\n",
    "\n",
    "def closest2(target_word, embeddings, count=10):\n",
    "    candidates = []\n",
    "    target_embedding = np.array(embeddings[target_word])\n",
    "    \n",
    "    for word in embeddings:\n",
    "        similarity = cosine_similarity(target_embedding, np.array(embeddings[word]))\n",
    "        candidates.append((word, similarity))    \n",
    "    \n",
    "    closest = sorted(candidates, key=lambda a: a[1], reverse=True)\n",
    "    closest_words = [x[0] for x in closest[0:count]]\n",
    "    return closest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['table',\n",
       " 'tables',\n",
       " 'place',\n",
       " 'bottom',\n",
       " 'room',\n",
       " 'side',\n",
       " 'sit',\n",
       " 'top',\n",
       " 'here',\n",
       " 'pool']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('table', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        if tolower:\n",
    "            keys_x = [x[key_x].lower() for x in sentence] \n",
    "        else:\n",
    "            keys_x = [x[key_x] for x in sentence] \n",
    "        keys_y = [y[key_y] for y in sentence]\n",
    "        \n",
    "        X.append(keys_x)\n",
    "        Y.append(keys_y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_words = []\n",
    "for sentence in X_train_symbs:\n",
    "    training_words += sentence\n",
    "training_words = sorted(set(training_words))\n",
    "\n",
    "chunks = []\n",
    "for sentence in Y_train_symbs:\n",
    "    chunks += sentence\n",
    "chunks = sorted(set(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(training_words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(set(embedded_words + training_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {}\n",
    "word2idx = {}\n",
    "for i, word in enumerate(vocabulary_words):\n",
    "    idx = i + 2\n",
    "    idx2word[idx] = word\n",
    "    word2idx[word] = idx\n",
    "\n",
    "idx2chunk = {}\n",
    "chunk2idx = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    idx = i + 1\n",
    "    idx2chunk[idx] = chunk\n",
    "    chunk2idx[chunk] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        embedding = embeddings_dict[word]\n",
    "        index = word2idx[word]\n",
    "        embedding_matrix[index] = embedding\n",
    "    else: \n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    X_train_idx.append([word2idx[word] for word in x])\n",
    "    Y_train_idx.append([chunk2idx[chunk] for chunk in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            torch.FloatTensor(embedding_matrix),\n",
    "            padding_idx=0)\n",
    "        if bidi_lstm:\n",
    "            self.lstm = nn.LSTM(embedding_dim, lstm_units, batch_first=True, bidirectional=True)\n",
    "        else:\n",
    "            self.lstm = nn.RNN(embedding_dim, lstm_units, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(in_features=lstm_units*2, out_features=nbr_classes, bias=True)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = torch.relu(lstm_out)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)    # cross entropy loss\n",
    "optimizer = torch.optim.RMSprop(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:18<00:00, 14.78it/s]\n",
      "100%|██████████| 280/280 [00:18<00:00, 15.47it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 16.23it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.93it/s]\n",
      "100%|██████████| 280/280 [00:18<00:00, 15.18it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.96it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 16.07it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 16.03it/s]\n",
      "100%|██████████| 280/280 [00:18<00:00, 15.41it/s]\n",
      "100%|██████████| 280/280 [00:19<00:00, 14.49it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 16.02it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.97it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.92it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 16.10it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = []\n",
    "for word in sentence:\n",
    "    if word in word2idx:\n",
    "        sentence_word_idxs.append(word2idx[word])\n",
    "    else:\n",
    "        sentence_word_idxs.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sent_chunk_predictions = model1(torch.tensor(sentence_word_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2591e-13, 1.6727e-07, 1.7112e-05, 5.5679e-10, 2.8525e-08, 2.4102e-06,\n",
       "        9.9993e-01, 1.2288e-06, 3.7018e-08, 5.1214e-07, 8.6132e-16, 1.3814e-09,\n",
       "        2.8275e-09, 7.8742e-09, 1.6321e-09, 7.8819e-10, 1.8816e-06, 4.0785e-09,\n",
       "        1.9034e-13, 1.8708e-10, 4.6705e-09, 1.0260e-09, 5.1331e-05],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    words_x = []\n",
    "    for word in x:\n",
    "        if word in word2idx:\n",
    "            words_x.append(word2idx[word])\n",
    "        else:\n",
    "            words_x.append(1)\n",
    "    X_test_idx.append(words_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-16.4768,  -5.3754,  -5.4338,  ...,  -4.5517,  -6.0378,  -1.2677],\n",
      "        [-18.6413,  -8.5650,  -3.2077,  ...,  -7.1976,  -2.9314,   0.8188],\n",
      "        [-20.7195,  -6.0646,  -4.9968,  ...,  -8.8244,  -7.2688,   0.4600],\n",
      "        ...,\n",
      "        [ -7.6633,  -1.6600,  -3.0575,  ..., -10.0991,  -3.9927,   4.2775],\n",
      "        [ -7.2299,  -1.4930,  -2.9579,  ...,  -9.8612,  -3.8953,   4.0819],\n",
      "        [ -6.7470,  -1.2939,  -2.8637,  ...,  -9.6612,  -3.8627,   3.9634]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-SBAR'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8984478751660027"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# Pierre's anwers: \n",
    "    # 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "    # 0.8579701751845953 lstm trainable 15 epochs\n",
    "    # 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "    # 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My answers:\n",
    " - 0.8984478751660027 lstm bidi ?trainable? 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
