{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1dadf34d410>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Git-Repos\\Language-Technology\\labs_2023\\Lab_5\\5-chunker.ipynb Cell 31\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_5/5-chunker.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# We read the embeddings\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_5/5-chunker.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m embeddings_dict \u001b[39m=\u001b[39m read_embeddings(embedding_file)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_5/5-chunker.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m embedded_words \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mlist\u001b[39m(embeddings_dict\u001b[39m.\u001b[39mkeys()))\n",
      "\u001b[1;32mc:\\Git-Repos\\Language-Technology\\labs_2023\\Lab_5\\5-chunker.ipynb Cell 31\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_5/5-chunker.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m embeddings \u001b[39m=\u001b[39m {}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_5/5-chunker.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m glove \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(file, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_5/5-chunker.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m glove:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_5/5-chunker.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     values \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_5/5-chunker.ipynb#X42sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     word \u001b[39m=\u001b[39m values[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m<frozen codecs>:319\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(array1, array2):\n",
    "        dot_product = np.dot(array1, array2)\n",
    "        cosine_similarity = dot_product/(np.linalg.norm(array1)*np.linalg.norm(array2))\n",
    "        return cosine_similarity\n",
    "\n",
    "def closest2(target_word, embeddings, count=10):\n",
    "    candidates = []\n",
    "    target_embedding = np.array(embeddings[target_word])\n",
    "    \n",
    "    for word in embeddings:\n",
    "        similarity = cosine_similarity(target_embedding, np.array(embeddings[word]))\n",
    "        candidates.append((word, similarity))    \n",
    "    \n",
    "    closest = sorted(candidates, key=lambda a: a[1], reverse=True)\n",
    "    closest_words = [x[0] for x in closest[0:count]]\n",
    "    return closest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['table',\n",
       " 'tables',\n",
       " 'place',\n",
       " 'bottom',\n",
       " 'room',\n",
       " 'side',\n",
       " 'sit',\n",
       " 'top',\n",
       " 'here',\n",
       " 'pool']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('table', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        if tolower:\n",
    "            keys_x = [x[key_x].lower() for x in sentence] \n",
    "        else:\n",
    "            keys_x = [x[key_x] for x in sentence] \n",
    "        keys_y = [y[key_y] for y in sentence]\n",
    "        \n",
    "        X.append(keys_x)\n",
    "        Y.append(keys_y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_words = []\n",
    "for sentence in X_train_symbs:\n",
    "    training_words += sentence\n",
    "training_words = sorted(set(training_words))\n",
    "\n",
    "chunks = []\n",
    "for sentence in Y_train_symbs:\n",
    "    chunks += sentence\n",
    "chunks = sorted(set(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(training_words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(set(embedded_words + training_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {}\n",
    "word2idx = {}\n",
    "for i, word in enumerate(vocabulary_words):\n",
    "    idx = i + 2\n",
    "    idx2word[idx] = word\n",
    "    word2idx[word] = idx\n",
    "\n",
    "idx2chunk = {}\n",
    "chunk2idx = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    idx = i + 1\n",
    "    idx2chunk[idx] = chunk\n",
    "    chunk2idx[chunk] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        embedding = embeddings_dict[word]\n",
    "        index = word2idx[word]\n",
    "        embedding_matrix[index] = embedding\n",
    "    else: \n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    X_train_idx.append([word2idx[word] for word in x])\n",
    "    Y_train_idx.append([chunk2idx[chunk] for chunk in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        ...\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        ...\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = ...\n",
    "optimizer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:12<00:00,  3.85it/s]\n",
      "100%|██████████| 280/280 [01:08<00:00,  4.10it/s]\n",
      "100%|██████████| 280/280 [01:07<00:00,  4.13it/s]\n",
      "100%|██████████| 280/280 [01:07<00:00,  4.14it/s]\n",
      "100%|██████████| 280/280 [01:06<00:00,  4.21it/s]\n",
      "100%|██████████| 280/280 [01:09<00:00,  4.04it/s]\n",
      "100%|██████████| 280/280 [01:09<00:00,  4.02it/s]\n",
      "100%|██████████| 280/280 [01:09<00:00,  4.02it/s]\n",
      "100%|██████████| 280/280 [01:08<00:00,  4.11it/s]\n",
      "100%|██████████| 280/280 [01:07<00:00,  4.14it/s]\n",
      "100%|██████████| 280/280 [01:06<00:00,  4.19it/s]\n",
      "100%|██████████| 280/280 [01:07<00:00,  4.16it/s]\n",
      "100%|██████████| 280/280 [01:07<00:00,  4.12it/s]\n",
      "100%|██████████| 280/280 [01:07<00:00,  4.16it/s]\n",
      "100%|██████████| 280/280 [01:06<00:00,  4.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes tensor([358640, 373606, 343335, 245002,      1,    873])\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sent_chunk_predictions = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2072e-13, 4.7664e-10, 3.5222e-09, 7.4905e-13, 8.2765e-10, 9.5403e-09,\n",
       "        1.0000e+00, 9.4836e-10, 3.9878e-12, 4.5347e-09, 1.2401e-11, 1.8891e-13,\n",
       "        1.4451e-13, 1.7238e-13, 1.3286e-12, 2.0025e-11, 9.5634e-09, 1.7781e-12,\n",
       "        1.2139e-11, 2.6272e-12, 5.4331e-11, 9.5586e-15, 1.6024e-06],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[ -7.0167,  -1.3971,  -2.6404,  ...,  -1.0799,  -1.3150,   4.7549],\n",
      "        [ -6.5066,  -4.5663,   1.0363,  ...,  -2.3344,   6.9481,   6.8664],\n",
      "        [-11.6368,  -2.9430,  -2.0845,  ...,  -4.6665,  -7.5087,   6.0453],\n",
      "        ...,\n",
      "        [ 20.2845,  -4.0088,  -3.6083,  ...,  -1.0157,  -5.1971,   0.3017],\n",
      "        [ 18.3593,  -3.3927,  -3.4281,  ...,  -0.7486,  -4.9716,  -0.0463],\n",
      "        [ 16.9232,  -2.7952,  -3.0611,  ...,  -0.5927,  -4.9505,  -0.2680]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-PP'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9000020716372148"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
