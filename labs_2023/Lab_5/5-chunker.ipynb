{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14e3eabd450>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(array1, array2):\n",
    "        dot_product = np.dot(array1, array2)\n",
    "        cosine_similarity = dot_product/(np.linalg.norm(array1)*np.linalg.norm(array2))\n",
    "        return cosine_similarity\n",
    "\n",
    "def closest2(target_word, embeddings, count=10):\n",
    "    candidates = []\n",
    "    target_embedding = np.array(embeddings[target_word])\n",
    "    \n",
    "    for word in embeddings:\n",
    "        similarity = cosine_similarity(target_embedding, np.array(embeddings[word]))\n",
    "        candidates.append((word, similarity))    \n",
    "    \n",
    "    closest = sorted(candidates, key=lambda a: a[1], reverse=True)\n",
    "    closest_words = [x[0] for x in closest[0:count]]\n",
    "    return closest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['table',\n",
       " 'tables',\n",
       " 'place',\n",
       " 'bottom',\n",
       " 'room',\n",
       " 'side',\n",
       " 'sit',\n",
       " 'top',\n",
       " 'here',\n",
       " 'pool']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('table', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        if tolower:\n",
    "            keys_x = [x[key_x].lower() for x in sentence] \n",
    "        else:\n",
    "            keys_x = [x[key_x] for x in sentence] \n",
    "        keys_y = [y[key_y] for y in sentence]\n",
    "        \n",
    "        X.append(keys_x)\n",
    "        Y.append(keys_y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_words = []\n",
    "for sentence in X_train_symbs:\n",
    "    training_words += sentence\n",
    "training_words = sorted(set(training_words))\n",
    "\n",
    "chunks = []\n",
    "for sentence in Y_train_symbs:\n",
    "    chunks += sentence\n",
    "chunks = sorted(set(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(training_words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(set(embedded_words + training_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {}\n",
    "word2idx = {}\n",
    "for i, word in enumerate(vocabulary_words):\n",
    "    idx = i + 2\n",
    "    idx2word[idx] = word\n",
    "    word2idx[word] = idx\n",
    "\n",
    "idx2chunk = {}\n",
    "chunk2idx = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    idx = i + 1\n",
    "    idx2chunk[idx] = chunk\n",
    "    chunk2idx[chunk] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        embedding = embeddings_dict[word]\n",
    "        index = word2idx[word]\n",
    "        embedding_matrix[index] = embedding\n",
    "    else: \n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    X_train_idx.append([word2idx[word] for word in x])\n",
    "    Y_train_idx.append([chunk2idx[chunk] for chunk in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "class Model(nn.Module):\n",
    "    bidi_lstm = False\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.bidi_lstm = bidi_lstm\n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            torch.FloatTensor(embedding_matrix),\n",
    "            padding_idx=0)\n",
    "        if bidi_lstm:\n",
    "            self.lstm = nn.LSTM(embedding_dim, lstm_units, batch_first=True, bidirectional=True)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(embedding_dim, lstm_units, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(in_features=lstm_units*2, out_features=nbr_classes, bias=True)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        if self.bidi_lstm:\n",
    "            lstm_out, _ = self.lstm(embeds)\n",
    "            lstm_out = torch.relu(lstm_out)\n",
    "            logits = self.fc(lstm_out)\n",
    "        else:\n",
    "            rnn_out, _ = self.rnn(embeds)\n",
    "            rnn_out = torch.relu(rnn_out)\n",
    "            logits = self.fc(rnn_out)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (rnn): RNN(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)    # cross entropy loss\n",
    "optimizer = torch.optim.RMSprop(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:50<00:00,  5.59it/s]\n",
      "100%|██████████| 280/280 [00:52<00:00,  5.32it/s]\n",
      "100%|██████████| 280/280 [00:53<00:00,  5.23it/s]\n",
      "100%|██████████| 280/280 [00:51<00:00,  5.49it/s]\n",
      "100%|██████████| 280/280 [00:50<00:00,  5.51it/s]\n",
      "100%|██████████| 280/280 [00:51<00:00,  5.45it/s]\n",
      "100%|██████████| 280/280 [00:50<00:00,  5.50it/s]\n",
      "100%|██████████| 280/280 [00:51<00:00,  5.43it/s]\n",
      "100%|██████████| 280/280 [00:50<00:00,  5.50it/s]\n",
      "100%|██████████| 280/280 [00:51<00:00,  5.49it/s]\n",
      "100%|██████████| 280/280 [00:51<00:00,  5.44it/s]\n",
      "100%|██████████| 280/280 [00:50<00:00,  5.57it/s]\n",
      "100%|██████████| 280/280 [00:52<00:00,  5.38it/s]\n",
      "100%|██████████| 280/280 [00:50<00:00,  5.51it/s]\n",
      "100%|██████████| 280/280 [00:51<00:00,  5.48it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = []\n",
    "for word in sentence:\n",
    "    if word in word2idx:\n",
    "        sentence_word_idxs.append(word2idx[word])\n",
    "    else:\n",
    "        sentence_word_idxs.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sent_chunk_predictions = model1(torch.tensor(sentence_word_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.9321e-12, 1.8109e-05, 7.7966e-05, 1.0659e-11, 5.1774e-07, 4.0178e-08,\n",
       "        9.9934e-01, 3.7012e-05, 9.7346e-08, 9.3135e-08, 1.6766e-19, 1.9073e-07,\n",
       "        2.1625e-07, 6.9930e-08, 2.1549e-08, 2.1008e-09, 1.4869e-05, 2.7147e-08,\n",
       "        2.0569e-12, 3.0236e-10, 4.2359e-10, 2.7615e-08, 5.0872e-04],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    words_x = []\n",
    "    for word in x:\n",
    "        if word in word2idx:\n",
    "            words_x.append(word2idx[word])\n",
    "        else:\n",
    "            words_x.append(1)\n",
    "    X_test_idx.append(words_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-17.5275,  -4.7567,  -7.6224,  ..., -10.7476,  -6.2164,   0.1915],\n",
      "        [-19.4616,  -8.5048,  -5.3878,  ..., -11.1219,  -4.2872,   0.6930],\n",
      "        [-19.8505,  -4.2814,  -2.5791,  ..., -11.6509,  -9.5714,   0.2806],\n",
      "        ...,\n",
      "        [-15.2892,  -4.3545,  -2.4782,  ...,  -8.0924,  -7.0015,   5.4736],\n",
      "        [-12.1949,  -2.6865,  -1.5773,  ...,  -7.5387,  -6.6551,   3.6813],\n",
      "        [ -8.5718,  -1.4972,  -1.2021,  ...,  -6.6405,  -6.6094,   2.5948]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-SBAR'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'B-NP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8942331593338305"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# Pierre's anwers: \n",
    "    # 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "    # 0.8579701751845953 lstm trainable 15 epochs\n",
    "    # 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "    # 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My answers:\n",
    " - 0.8984478751660027 lstm bidi ?trainable? 15 epochs\n",
    " - 0.8942331593338305 RNN ?trainable? 15 epochs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
