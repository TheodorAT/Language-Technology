{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2c93c28a730>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(array1, array2):\n",
    "        dot_product = np.dot(array1, array2)\n",
    "        cosine_similarity = dot_product/(np.linalg.norm(array1)*np.linalg.norm(array2))\n",
    "        return cosine_similarity\n",
    "\n",
    "def closest2(target_word, embeddings, count=10):\n",
    "    candidates = []\n",
    "    target_embedding = np.array(embeddings[target_word])\n",
    "    \n",
    "    for word in embeddings:\n",
    "        similarity = cosine_similarity(target_embedding, np.array(embeddings[word]))\n",
    "        candidates.append((word, similarity))    \n",
    "    \n",
    "    closest = sorted(candidates, key=lambda a: a[1], reverse=True)\n",
    "    closest_words = [x[0] for x in closest[0:count]]\n",
    "    return closest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['table',\n",
       " 'tables',\n",
       " 'place',\n",
       " 'bottom',\n",
       " 'room',\n",
       " 'side',\n",
       " 'sit',\n",
       " 'top',\n",
       " 'here',\n",
       " 'pool']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('table', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        if tolower:\n",
    "            keys_x = [x[key_x].lower() for x in sentence] \n",
    "        else:\n",
    "            keys_x = [x[key_x] for x in sentence] \n",
    "        keys_y = [y[key_y] for y in sentence]\n",
    "        \n",
    "        X.append(keys_x)\n",
    "        Y.append(keys_y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['confidence', 'in', 'the', 'pound', 'is', 'widely', 'expected', 'to', 'take', 'another', 'sharp', 'dive', 'if', 'trade', 'figures', 'for', 'september', ',', 'due', 'for', 'release', 'tomorrow', ',', 'fail', 'to', 'show', 'a', 'substantial', 'improvement', 'from', 'july', 'and', 'august', \"'s\", 'near-record', 'deficits', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_words = []\n",
    "for sentence in X_train_symbs:\n",
    "    training_words += sentence\n",
    "training_words = sorted(set(training_words))\n",
    "\n",
    "chunks = []\n",
    "for sentence in Y_train_symbs:\n",
    "    chunks += sentence\n",
    "chunks = sorted(set(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(training_words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(set(embedded_words + training_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {}\n",
    "word2idx = {}\n",
    "for i, word in enumerate(vocabulary_words):\n",
    "    idx = i + 2\n",
    "    idx2word[idx] = word\n",
    "    word2idx[word] = idx\n",
    "\n",
    "idx2chunk = {}\n",
    "chunk2idx = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    idx = i + 1\n",
    "    idx2chunk[idx] = chunk\n",
    "    chunk2idx[chunk] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        embedding = embeddings_dict[word]\n",
    "        index = word2idx[word]\n",
    "        embedding_matrix[index] = embedding\n",
    "    else: \n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    X_train_idx.append([word2idx[word] for word in x])\n",
    "    Y_train_idx.append([chunk2idx[chunk] for chunk in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(Y_train_padded[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "class Model(nn.Module):\n",
    "    bidi_lstm = False\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, lstm, freeze):\n",
    "        super().__init__()\n",
    "        self.bidi_lstm = lstm\n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            torch.FloatTensor(embedding_matrix),\n",
    "            padding_idx=0,\n",
    "            freeze=freeze) # Trainable or non-trainable embedding layer.\n",
    "        if lstm:\n",
    "            self.lstm = nn.LSTM(embedding_dim, lstm_units, batch_first=True, bidirectional=True)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(embedding_dim, lstm_units, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(in_features=lstm_units*2, out_features=nbr_classes, bias=True)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        if self.bidi_lstm:\n",
    "            lstm_out, _ = self.lstm(embeds)\n",
    "            lstm_out = torch.relu(lstm_out)\n",
    "            logits = self.fc(lstm_out)\n",
    "        else:\n",
    "            rnn_out, _ = self.rnn(embeds)\n",
    "            rnn_out = torch.relu(rnn_out)\n",
    "            logits = self.fc(rnn_out)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, lstm=True, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)    # cross entropy loss\n",
    "optimizer = torch.optim.RMSprop(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:17<00:00, 16.28it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 16.05it/s]\n",
      "100%|██████████| 280/280 [00:16<00:00, 16.73it/s]\n",
      "100%|██████████| 280/280 [00:18<00:00, 15.43it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.69it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.67it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.65it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.66it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.63it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.65it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.72it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.70it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.75it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.81it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.83it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = []\n",
    "for word in sentence:\n",
    "    if word in word2idx:\n",
    "        sentence_word_idxs.append(word2idx[word])\n",
    "    else:\n",
    "        sentence_word_idxs.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sent_chunk_predictions = model1(torch.tensor(sentence_word_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.3291e-12, 8.7231e-06, 2.1488e-05, 2.1747e-08, 2.0735e-06, 1.8751e-05,\n",
       "        9.9953e-01, 1.5430e-05, 7.6975e-08, 2.1337e-06, 1.1430e-13, 1.3433e-07,\n",
       "        1.2564e-07, 2.9458e-08, 1.4594e-08, 4.5200e-08, 1.0727e-05, 3.0787e-08,\n",
       "        1.5510e-10, 4.7384e-09, 2.3731e-08, 7.4597e-09, 3.8714e-04],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    words_x = []\n",
    "    for word in x:\n",
    "        if word in word2idx:\n",
    "            words_x.append(word2idx[word])\n",
    "        else:\n",
    "            words_x.append(1)\n",
    "    X_test_idx.append(words_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-17.0833,  -3.3592,  -4.6877,  ...,  -8.4334,  -5.4558,  -1.0859],\n",
      "        [-19.0877,  -7.8169,  -2.8199,  ...,  -7.9724,  -4.1111,   0.3969],\n",
      "        [-19.9074,  -3.8485,  -3.3330,  ...,  -9.4320,  -8.7388,   0.2252],\n",
      "        ...,\n",
      "        [ -8.1839,  -2.2514,  -3.6725,  ...,  -9.0154,  -5.5288,   5.2552],\n",
      "        [ -7.4431,  -2.1812,  -3.5760,  ...,  -8.2806,  -5.2640,   4.9412],\n",
      "        [ -6.6810,  -2.0857,  -3.4952,  ...,  -7.7478,  -5.0636,   4.7151]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-SBAR'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9030801416823746"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# Pierre's anwers: \n",
    "    # 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "    # 0.8579701751845953 lstm trainable 15 epochs\n",
    "    # 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "    # 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My answers:\n",
    " - 0.8984478751660027 LSTM bidirectional trainable 15 epochs\n",
    " - 0.9030801416823746 LSTM bidirectional nontrainable 15 epochs\n",
    " - 0.8942331593338305 RNN bidirectional trainable 15 epochs \n",
    " - 0.8797836766709326 RNN bidirectional nontrainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
