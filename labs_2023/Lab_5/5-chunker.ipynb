{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2a5a75cd3f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(array1, array2):\n",
    "        dot_product = np.dot(array1, array2)\n",
    "        cosine_similarity = dot_product/(np.linalg.norm(array1)*np.linalg.norm(array2))\n",
    "        return cosine_similarity\n",
    "\n",
    "def closest2(target_word, embeddings, count=10):\n",
    "    candidates = []\n",
    "    target_embedding = np.array(embeddings[target_word])\n",
    "    \n",
    "    for word in embeddings:\n",
    "        similarity = cosine_similarity(target_embedding, np.array(embeddings[word]))\n",
    "        candidates.append((word, similarity))    \n",
    "    \n",
    "    closest = sorted(candidates, key=lambda a: a[1], reverse=True)\n",
    "    closest_words = [x[0] for x in closest[0:count]]\n",
    "    return closest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['table',\n",
       " 'tables',\n",
       " 'place',\n",
       " 'bottom',\n",
       " 'room',\n",
       " 'side',\n",
       " 'sit',\n",
       " 'top',\n",
       " 'here',\n",
       " 'pool']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('table', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        if tolower:\n",
    "            keys_x = [x[key_x].lower() for x in sentence] \n",
    "        else:\n",
    "            keys_x = [x[key_x] for x in sentence] \n",
    "        keys_y = [y[key_y] for y in sentence]\n",
    "        \n",
    "        X.append(keys_x)\n",
    "        Y.append(keys_y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['confidence', 'in', 'the', 'pound', 'is', 'widely', 'expected', 'to', 'take', 'another', 'sharp', 'dive', 'if', 'trade', 'figures', 'for', 'september', ',', 'due', 'for', 'release', 'tomorrow', ',', 'fail', 'to', 'show', 'a', 'substantial', 'improvement', 'from', 'july', 'and', 'august', \"'s\", 'near-record', 'deficits', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_words = []\n",
    "for sentence in X_train_symbs:\n",
    "    training_words += sentence\n",
    "training_words = sorted(set(training_words))\n",
    "\n",
    "chunks = []\n",
    "for sentence in Y_train_symbs:\n",
    "    chunks += sentence\n",
    "chunks = sorted(set(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(training_words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(set(embedded_words + training_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {}\n",
    "word2idx = {}\n",
    "for i, word in enumerate(vocabulary_words):\n",
    "    idx = i + 2\n",
    "    idx2word[idx] = word\n",
    "    word2idx[word] = idx\n",
    "\n",
    "idx2chunk = {}\n",
    "chunk2idx = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    idx = i + 1\n",
    "    idx2chunk[idx] = chunk\n",
    "    chunk2idx[chunk] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        embedding = embeddings_dict[word]\n",
    "        index = word2idx[word]\n",
    "        embedding_matrix[index] = embedding\n",
    "    else: \n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    X_train_idx.append([word2idx[word] for word in x])\n",
    "    Y_train_idx.append([chunk2idx[chunk] for chunk in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n",
      "torch.Size([78])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(Y_train_padded[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "class Model(nn.Module):\n",
    "    bidi_lstm = False\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, lstm, freeze):\n",
    "        super().__init__()\n",
    "        self.bidi_lstm = lstm\n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            torch.FloatTensor(embedding_matrix),\n",
    "            padding_idx=0,\n",
    "            freeze=freeze) # Trainable or non-trainable embedding layer.\n",
    "        if lstm:\n",
    "            self.lstm = nn.LSTM(embedding_dim, lstm_units, batch_first=True, bidirectional=True)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(embedding_dim, lstm_units, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(in_features=lstm_units*2, out_features=nbr_classes, bias=True)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        if self.bidi_lstm:\n",
    "            lstm_out, _ = self.lstm(embeds)\n",
    "            lstm_out = torch.relu(lstm_out)\n",
    "            logits = self.fc(lstm_out)\n",
    "        else:\n",
    "            rnn_out, _ = self.rnn(embeds)\n",
    "            rnn_out = torch.relu(rnn_out)\n",
    "            logits = self.fc(rnn_out)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, lstm=False, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (rnn): RNN(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)    # cross entropy loss\n",
    "optimizer = torch.optim.RMSprop(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:44<00:00,  6.35it/s]\n",
      "100%|██████████| 280/280 [00:42<00:00,  6.52it/s]\n",
      "100%|██████████| 280/280 [00:44<00:00,  6.36it/s]\n",
      "100%|██████████| 280/280 [00:43<00:00,  6.49it/s]\n",
      "100%|██████████| 280/280 [00:43<00:00,  6.49it/s]\n",
      "100%|██████████| 280/280 [00:44<00:00,  6.23it/s]\n",
      "100%|██████████| 280/280 [00:48<00:00,  5.81it/s]\n",
      "100%|██████████| 280/280 [00:44<00:00,  6.33it/s]\n",
      "100%|██████████| 280/280 [00:43<00:00,  6.50it/s]\n",
      "100%|██████████| 280/280 [00:43<00:00,  6.40it/s]\n",
      "100%|██████████| 280/280 [00:44<00:00,  6.35it/s]\n",
      "100%|██████████| 280/280 [00:43<00:00,  6.45it/s]\n",
      "100%|██████████| 280/280 [00:43<00:00,  6.47it/s]\n",
      "100%|██████████| 280/280 [00:43<00:00,  6.43it/s]\n",
      "100%|██████████| 280/280 [00:47<00:00,  5.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = []\n",
    "for word in sentence:\n",
    "    if word in word2idx:\n",
    "        sentence_word_idxs.append(word2idx[word])\n",
    "    else:\n",
    "        sentence_word_idxs.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sent_chunk_predictions = model1(torch.tensor(sentence_word_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.1905e-13, 3.0087e-07, 1.6911e-05, 5.8861e-10, 8.5236e-08, 2.8024e-07,\n",
       "        9.9993e-01, 3.5924e-07, 3.1937e-08, 3.1289e-06, 1.1330e-21, 4.8189e-09,\n",
       "        3.0270e-08, 2.5226e-08, 1.3742e-08, 8.9084e-09, 4.6014e-06, 1.0285e-08,\n",
       "        2.0166e-13, 2.3666e-09, 4.6257e-12, 1.3839e-10, 4.8309e-05],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    words_x = []\n",
    "    for word in x:\n",
    "        if word in word2idx:\n",
    "            words_x.append(word2idx[word])\n",
    "        else:\n",
    "            words_x.append(1)\n",
    "    X_test_idx.append(words_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-17.8405,  -5.6535,  -8.0523,  ..., -10.8921,  -6.9533,  -1.4177],\n",
      "        [-20.9761,  -8.8936,  -2.7843,  ..., -12.5912,  -3.8545,   1.7479],\n",
      "        [-19.9266,  -6.2365,  -3.4273,  ..., -14.6883,  -9.0852,  -0.8647],\n",
      "        ...,\n",
      "        [-14.7361,  -3.0727,  -2.2481,  ...,  -3.9481,  -5.3917,   4.2706],\n",
      "        [-11.3672,  -1.4989,  -2.7426,  ...,  -3.4728,  -4.2358,   2.8628],\n",
      "        [ -8.3026,  -0.0404,  -2.2512,  ...,  -3.0131,  -4.6141,   2.2577]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-SBAR'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8797836766709326"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# Pierre's anwers: \n",
    "    # 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "    # 0.8579701751845953 lstm trainable 15 epochs\n",
    "    # 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "    # 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My answers:\n",
    " - 0.8984478751660027 lstm bidirectional trainable 15 epochs\n",
    " - 0.8942331593338305 RNN bidirectional trainable 15 epochs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
