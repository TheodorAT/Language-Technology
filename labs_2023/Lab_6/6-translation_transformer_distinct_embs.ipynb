{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level Encoder-Decoder Transformer\n",
    "\n",
    "In this notebook, you will create a machine-translation system that will accept a sentence in a language of your choice and translate it in another language also of your choice.\n",
    "\n",
    "As architecture, you will use the transformer described in _Attention Is All You Need_ (https://arxiv.org/abs/1706.03762). The complete programming from scratch of such an architecture would take more time than that of a lab. That is why the notebook contains all the code. You will merely run separate modules and assemble them. In the end, this will result in a complete encoder-decoder. \n",
    "\n",
    "You will train this encoder-decoder for a translation task and you will observe its performance. To make training possible, you will use characters as input and output instead of words or subwords.\n",
    "\n",
    "The power of the student's computers vary greatly. In consequence, depending on your machine, reduce the size of the dataset and simplify the architecture (use less stacks, less heads) as much as you need to be able to run the program quickly. After the lab, should you wish it, feel free to improve the program and build a more realistic translation system.\n",
    "\n",
    "Finally, please do not run the cells blindly. The objective of the lab is that you understand the transformer by executing it step-by-step. The instructors will ask you to explain cell.\n",
    "\n",
    "Acknowledgments: As starting point to write the notebook, we used a tutorial from PyTorch available at: https://pytorch.org/tutorials/beginner/translation_transformer.html?highlight=translation\n",
    "\n",
    "We modified it to remove the torchtext dependencies and use a character input.\n",
    "\n",
    "__Pierre Nugues__ and __Marcus Klang__\n",
    "\n",
    "History: \n",
    "- V1, Pierre creation from Pytorch tutorial\n",
    "- V2, Marcus, answering questions and improvements notably dataloader\n",
    "- V3, Pierre, separate train and val, cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This program shows how to implement a basic character-level translation model with a transformer. You will translate the sentences from English to French or another language character by character. Note that a more elaborate model would use words or subwords.\n",
    "\n",
    "### Summary of the algorithm\n",
    "- We start with input sequences from a language (e.g. English sentences)\n",
    "    and corresponding target sequences from another language\n",
    "    (e.g. French sentences).\n",
    "- A transformer encoder encodes the source sentence. The result is called `memory` in the program;\n",
    "- A transformer decoder uses the encoded source sentence and an auto-regressive process to generate the target sequence.\n",
    "- The loss is the cross-entropy ebtween the decoded characters and the target ones\n",
    "- In inference mode, when we decode unknown input sequences using these steps:\n",
    "    - Encode the input sequence (`memory`)\n",
    "    - Feed the decoder with the encoded sequence \n",
    "    - Start with a target sequence of size 1\n",
    "        (just the start-of-sequence character)\n",
    "    - Sample the next character using these predictions\n",
    "        (we simply use argmax, the second output of `torch.max()`).\n",
    "    - Append the sampled character to the target sequence\n",
    "    - Repeat until we generate the end-of-sequence character or we\n",
    "        hit the character limit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the http://www.manythings.org/anki/ site and select a corpus with at least 10,000 pairs. You should understand the target language well. Ideally, it should be your mother tongue.\n",
    "Then uncomment and run the lines below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  1  773k    1 14271    0     0  17170      0  0:00:46 --:--:--  0:00:46 17193\n",
      " 30  773k   30  232k    0     0   118k      0  0:00:06  0:00:01  0:00:05  118k\n",
      "100  773k  100  773k    0     0   299k      0  0:00:02  0:00:02 --:--:--  299k\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#!curl -O http://www.manythings.org/anki/swe-eng.zip\n",
    "#!unzip swe-eng.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "from torch.utils.data import dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23ceff87f70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "We select the computing architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "# elif torch.backends.mps.is_available():\n",
    "#    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "DEVICE = torch.device(device)\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'corpus/swe.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24610"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 80000  # Number of samples to train on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split(\"\\t\")\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Tom mad?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Är Tom arg?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[500]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_PERCENTAGE = 0.8\n",
    "train_val = int(TRAIN_PERCENTAGE * num_samples)\n",
    "train_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shuffle the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pairs = list(zip(input_texts, target_texts))\n",
    "random.shuffle(text_pairs)\n",
    "input_texts, target_texts = zip(*text_pairs)\n",
    "input_texts, target_texts = list(input_texts), list(target_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_texts = input_texts[:train_val]\n",
    "train_target_texts = target_texts[:train_val]\n",
    "\n",
    "val_input_texts = input_texts[train_val:]\n",
    "val_target_texts = target_texts[train_val:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = set(''.join(train_input_texts))\n",
    "target_characters = set(''.join(train_target_texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0, '<pad>': 1, '<bos>': 2, '<eos>': 3}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_symbols_dict = dict(\n",
    "    zip(special_symbols, [UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX]))\n",
    "special_symbols_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The input and output symbols\n",
    "The language pair shares the same vocabulary as in _Attention Is All You Need_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " '!',\n",
       " '\"',\n",
       " '%',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " 'Ä',\n",
       " 'Å',\n",
       " 'Ö',\n",
       " 'à',\n",
       " 'ä',\n",
       " 'å',\n",
       " 'é',\n",
       " 'ö',\n",
       " 'ü',\n",
       " '’',\n",
       " '”',\n",
       " '€']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = sorted(list(set.union(input_characters, target_characters)))\n",
    "characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 4,\n",
       " '!': 5,\n",
       " '\"': 6,\n",
       " '%': 7,\n",
       " \"'\": 8,\n",
       " ',': 9,\n",
       " '-': 10,\n",
       " '.': 11,\n",
       " '0': 12,\n",
       " '1': 13,\n",
       " '2': 14,\n",
       " '3': 15,\n",
       " '4': 16,\n",
       " '5': 17,\n",
       " '6': 18,\n",
       " '7': 19,\n",
       " '8': 20,\n",
       " '9': 21,\n",
       " ':': 22,\n",
       " '?': 23,\n",
       " 'A': 24,\n",
       " 'B': 25,\n",
       " 'C': 26,\n",
       " 'D': 27,\n",
       " 'E': 28,\n",
       " 'F': 29,\n",
       " 'G': 30,\n",
       " 'H': 31,\n",
       " 'I': 32,\n",
       " 'J': 33,\n",
       " 'K': 34,\n",
       " 'L': 35,\n",
       " 'M': 36,\n",
       " 'N': 37,\n",
       " 'O': 38,\n",
       " 'P': 39,\n",
       " 'Q': 40,\n",
       " 'R': 41,\n",
       " 'S': 42,\n",
       " 'T': 43,\n",
       " 'U': 44,\n",
       " 'V': 45,\n",
       " 'W': 46,\n",
       " 'Y': 47,\n",
       " 'Z': 48,\n",
       " 'a': 49,\n",
       " 'b': 50,\n",
       " 'c': 51,\n",
       " 'd': 52,\n",
       " 'e': 53,\n",
       " 'f': 54,\n",
       " 'g': 55,\n",
       " 'h': 56,\n",
       " 'i': 57,\n",
       " 'j': 58,\n",
       " 'k': 59,\n",
       " 'l': 60,\n",
       " 'm': 61,\n",
       " 'n': 62,\n",
       " 'o': 63,\n",
       " 'p': 64,\n",
       " 'q': 65,\n",
       " 'r': 66,\n",
       " 's': 67,\n",
       " 't': 68,\n",
       " 'u': 69,\n",
       " 'v': 70,\n",
       " 'w': 71,\n",
       " 'x': 72,\n",
       " 'y': 73,\n",
       " 'z': 74,\n",
       " 'Ä': 75,\n",
       " 'Å': 76,\n",
       " 'Ö': 77,\n",
       " 'à': 78,\n",
       " 'ä': 79,\n",
       " 'å': 80,\n",
       " 'é': 81,\n",
       " 'ö': 82,\n",
       " 'ü': 83,\n",
       " '’': 84,\n",
       " '”': 85,\n",
       " '€': 86}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2idx = {char: i for i, char in enumerate(characters, start=4)}\n",
    "token2idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 4,\n",
       " '!': 5,\n",
       " '\"': 6,\n",
       " '%': 7,\n",
       " \"'\": 8,\n",
       " ',': 9,\n",
       " '-': 10,\n",
       " '.': 11,\n",
       " '0': 12,\n",
       " '1': 13,\n",
       " '2': 14,\n",
       " '3': 15,\n",
       " '4': 16,\n",
       " '5': 17,\n",
       " '6': 18,\n",
       " '7': 19,\n",
       " '8': 20,\n",
       " '9': 21,\n",
       " ':': 22,\n",
       " '?': 23,\n",
       " 'A': 24,\n",
       " 'B': 25,\n",
       " 'C': 26,\n",
       " 'D': 27,\n",
       " 'E': 28,\n",
       " 'F': 29,\n",
       " 'G': 30,\n",
       " 'H': 31,\n",
       " 'I': 32,\n",
       " 'J': 33,\n",
       " 'K': 34,\n",
       " 'L': 35,\n",
       " 'M': 36,\n",
       " 'N': 37,\n",
       " 'O': 38,\n",
       " 'P': 39,\n",
       " 'Q': 40,\n",
       " 'R': 41,\n",
       " 'S': 42,\n",
       " 'T': 43,\n",
       " 'U': 44,\n",
       " 'V': 45,\n",
       " 'W': 46,\n",
       " 'Y': 47,\n",
       " 'Z': 48,\n",
       " 'a': 49,\n",
       " 'b': 50,\n",
       " 'c': 51,\n",
       " 'd': 52,\n",
       " 'e': 53,\n",
       " 'f': 54,\n",
       " 'g': 55,\n",
       " 'h': 56,\n",
       " 'i': 57,\n",
       " 'j': 58,\n",
       " 'k': 59,\n",
       " 'l': 60,\n",
       " 'm': 61,\n",
       " 'n': 62,\n",
       " 'o': 63,\n",
       " 'p': 64,\n",
       " 'q': 65,\n",
       " 'r': 66,\n",
       " 's': 67,\n",
       " 't': 68,\n",
       " 'u': 69,\n",
       " 'v': 70,\n",
       " 'w': 71,\n",
       " 'x': 72,\n",
       " 'y': 73,\n",
       " 'z': 74,\n",
       " 'Ä': 75,\n",
       " 'Å': 76,\n",
       " 'Ö': 77,\n",
       " 'à': 78,\n",
       " 'ä': 79,\n",
       " 'å': 80,\n",
       " 'é': 81,\n",
       " 'ö': 82,\n",
       " 'ü': 83,\n",
       " '’': 84,\n",
       " '”': 85,\n",
       " '€': 86,\n",
       " '<unk>': 0,\n",
       " '<pad>': 1,\n",
       " '<bos>': 2,\n",
       " '<eos>': 3}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2idx.update(special_symbols_dict)\n",
    "token2idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2token = {v: k for k, v in token2idx.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2codes(texts, token2idx):\n",
    "    codes = []\n",
    "    for text in texts:\n",
    "        text_l = ['<bos>'] + list(text) + ['<eos>']\n",
    "        codes += torch.tensor([list(map(lambda x: token2idx.get(x, 0), text_l))]) # <unk> -> 0\n",
    "    return codes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"There'll be plenty of time for that later.\",\n",
       "  'Summer is over.',\n",
       "  'They were caught red-handed.'],\n",
       " ['Det kommer det att finnas mycket tid för senare.',\n",
       "  'Sommaren är över.',\n",
       "  'De blev tagna på bar gärning.'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_texts[:3], train_target_texts[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 2, 43, 56, 53, 66, 53,  8, 60, 60,  4, 50, 53,  4, 64, 60, 53, 62, 68,\n",
       "         73,  4, 63, 54,  4, 68, 57, 61, 53,  4, 54, 63, 66,  4, 68, 56, 49, 68,\n",
       "          4, 60, 49, 68, 53, 66, 11,  3]),\n",
       " tensor([ 2, 42, 69, 61, 61, 53, 66,  4, 57, 67,  4, 63, 70, 53, 66, 11,  3]),\n",
       " tensor([ 2, 43, 56, 53, 73,  4, 71, 53, 66, 53,  4, 51, 49, 69, 55, 56, 68,  4,\n",
       "         66, 53, 52, 10, 56, 49, 62, 52, 53, 52, 11,  3])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2codes(train_input_texts, token2idx)[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 2, 27, 53, 68,  4, 59, 63, 61, 61, 53, 66,  4, 52, 53, 68,  4, 49, 68,\n",
       "         68,  4, 54, 57, 62, 62, 49, 67,  4, 61, 73, 51, 59, 53, 68,  4, 68, 57,\n",
       "         52,  4, 54, 82, 66,  4, 67, 53, 62, 49, 66, 53, 11,  3]),\n",
       " tensor([ 2, 42, 63, 61, 61, 49, 66, 53, 62,  4, 79, 66,  4, 82, 70, 53, 66, 11,\n",
       "          3]),\n",
       " tensor([ 2, 27, 53,  4, 50, 60, 53, 70,  4, 68, 49, 55, 62, 49,  4, 64, 80,  4,\n",
       "         50, 49, 66,  4, 55, 79, 66, 62, 57, 62, 55, 11,  3])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2codes(train_target_texts, token2idx)[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codes2text(codes, idx2token):\n",
    "    texts = []\n",
    "    for code in codes:\n",
    "        code_l = list(code)\n",
    "        texts += [list(map(lambda x: idx2token.get(x.item(), 0), code_l))]\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<bos>',\n",
       "  'T',\n",
       "  'h',\n",
       "  'e',\n",
       "  'r',\n",
       "  'e',\n",
       "  \"'\",\n",
       "  'l',\n",
       "  'l',\n",
       "  ' ',\n",
       "  'b',\n",
       "  'e',\n",
       "  ' ',\n",
       "  'p',\n",
       "  'l',\n",
       "  'e',\n",
       "  'n',\n",
       "  't',\n",
       "  'y',\n",
       "  ' ',\n",
       "  'o',\n",
       "  'f',\n",
       "  ' ',\n",
       "  't',\n",
       "  'i',\n",
       "  'm',\n",
       "  'e',\n",
       "  ' ',\n",
       "  'f',\n",
       "  'o',\n",
       "  'r',\n",
       "  ' ',\n",
       "  't',\n",
       "  'h',\n",
       "  'a',\n",
       "  't',\n",
       "  ' ',\n",
       "  'l',\n",
       "  'a',\n",
       "  't',\n",
       "  'e',\n",
       "  'r',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " ['<bos>',\n",
       "  'S',\n",
       "  'u',\n",
       "  'm',\n",
       "  'm',\n",
       "  'e',\n",
       "  'r',\n",
       "  ' ',\n",
       "  'i',\n",
       "  's',\n",
       "  ' ',\n",
       "  'o',\n",
       "  'v',\n",
       "  'e',\n",
       "  'r',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " ['<bos>',\n",
       "  'T',\n",
       "  'h',\n",
       "  'e',\n",
       "  'y',\n",
       "  ' ',\n",
       "  'w',\n",
       "  'e',\n",
       "  'r',\n",
       "  'e',\n",
       "  ' ',\n",
       "  'c',\n",
       "  'a',\n",
       "  'u',\n",
       "  'g',\n",
       "  'h',\n",
       "  't',\n",
       "  ' ',\n",
       "  'r',\n",
       "  'e',\n",
       "  'd',\n",
       "  '-',\n",
       "  'h',\n",
       "  'a',\n",
       "  'n',\n",
       "  'd',\n",
       "  'e',\n",
       "  'd',\n",
       "  '.',\n",
       "  '<eos>']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes2text(text2codes(train_input_texts, token2idx)[:3], idx2token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Embeddings\n",
    "\n",
    "Same as https://pytorch.org/tutorials/beginner/translation_transformer.html?highlight=translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `register_buffer` is a way to exclude `pos_embeddings` from being a parameter and stored as state, essentially a way to register a computed constant. It will not be modified by the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super().__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)\n",
    "                        * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PositionalEncoding(10, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1, 5, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111,\n",
       "          0.0000, 1.1111],\n",
       "         [0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111,\n",
       "          0.0000, 1.1111],\n",
       "         [0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 0.0000, 0.0000, 1.1111,\n",
       "          0.0000, 1.1111],\n",
       "         [0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111,\n",
       "          0.0000, 1.1111]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe(torch.zeros(1, 5, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "\n",
    "Same as https://pytorch.org/tutorials/beginner/translation_transformer.html?highlight=translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:   \n",
    "- `transformer.encoder(...)` is equivalent to a call of TransformerEncoder(...), i.e https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html    \n",
    "- `transformer.decoder(...)` is equivalent to a call of TransformerDecoder(...), i.e https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html   \n",
    "- These are created internally by the transformer layer:\n",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#Transformer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "            self.tgt_tok_emb(tgt)), memory,\n",
    "            tgt_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float(\n",
    "        '-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_square_subsequent_mask(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),\n",
    "                           device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1).type(torch.float32)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = pad_sequence(text2codes(\n",
    "    train_input_texts[:3], token2idx), padding_value=PAD_IDX)\n",
    "tgt = pad_sequence(text2codes(\n",
    "    train_target_texts[:3], token2idx), padding_value=PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"There'll be plenty of time for that later.\",\n",
       "  'Summer is over.',\n",
       "  'They were caught red-handed.'],\n",
       " ['Det kommer det att finnas mycket tid för senare.',\n",
       "  'Sommaren är över.',\n",
       "  'De blev tagna på bar gärning.'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_texts[:3], train_target_texts[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensors. Note the batch dimension is the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  2,  2],\n",
       "        [43, 42, 43],\n",
       "        [56, 69, 56],\n",
       "        [53, 61, 53],\n",
       "        [66, 61, 73],\n",
       "        [53, 53,  4],\n",
       "        [ 8, 66, 71],\n",
       "        [60,  4, 53],\n",
       "        [60, 57, 66],\n",
       "        [ 4, 67, 53],\n",
       "        [50,  4,  4],\n",
       "        [53, 63, 51],\n",
       "        [ 4, 70, 49],\n",
       "        [64, 53, 69],\n",
       "        [60, 66, 55],\n",
       "        [53, 11, 56],\n",
       "        [62,  3, 68],\n",
       "        [68,  1,  4],\n",
       "        [73,  1, 66],\n",
       "        [ 4,  1, 53],\n",
       "        [63,  1, 52],\n",
       "        [54,  1, 10],\n",
       "        [ 4,  1, 56],\n",
       "        [68,  1, 49],\n",
       "        [57,  1, 62],\n",
       "        [61,  1, 52],\n",
       "        [53,  1, 53],\n",
       "        [ 4,  1, 52],\n",
       "        [54,  1, 11],\n",
       "        [63,  1,  3],\n",
       "        [66,  1,  1],\n",
       "        [ 4,  1,  1],\n",
       "        [68,  1,  1],\n",
       "        [56,  1,  1],\n",
       "        [49,  1,  1],\n",
       "        [68,  1,  1],\n",
       "        [ 4,  1,  1],\n",
       "        [60,  1,  1],\n",
       "        [49,  1,  1],\n",
       "        [68,  1,  1],\n",
       "        [53,  1,  1],\n",
       "        [66,  1,  1],\n",
       "        [11,  1,  1],\n",
       "        [ 3,  1,  1]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  2,  2],\n",
       "        [27, 42, 27],\n",
       "        [53, 63, 53],\n",
       "        [68, 61,  4],\n",
       "        [ 4, 61, 50],\n",
       "        [59, 49, 60],\n",
       "        [63, 66, 53],\n",
       "        [61, 53, 70],\n",
       "        [61, 62,  4],\n",
       "        [53,  4, 68],\n",
       "        [66, 79, 49],\n",
       "        [ 4, 66, 55],\n",
       "        [52,  4, 62],\n",
       "        [53, 82, 49],\n",
       "        [68, 70,  4],\n",
       "        [ 4, 53, 64],\n",
       "        [49, 66, 80],\n",
       "        [68, 11,  4],\n",
       "        [68,  3, 50],\n",
       "        [ 4,  1, 49],\n",
       "        [54,  1, 66],\n",
       "        [57,  1,  4],\n",
       "        [62,  1, 55],\n",
       "        [62,  1, 79],\n",
       "        [49,  1, 66],\n",
       "        [67,  1, 62],\n",
       "        [ 4,  1, 57],\n",
       "        [61,  1, 62],\n",
       "        [73,  1, 55],\n",
       "        [51,  1, 11],\n",
       "        [59,  1,  3],\n",
       "        [53,  1,  1],\n",
       "        [68,  1,  1],\n",
       "        [ 4,  1,  1],\n",
       "        [68,  1,  1],\n",
       "        [57,  1,  1],\n",
       "        [52,  1,  1],\n",
       "        [ 4,  1,  1],\n",
       "        [54,  1,  1],\n",
       "        [82,  1,  1],\n",
       "        [66,  1,  1],\n",
       "        [ 4,  1,  1],\n",
       "        [67,  1,  1],\n",
       "        [53,  1,  1],\n",
       "        [62,  1,  1],\n",
       "        [49,  1,  1],\n",
       "        [66,  1,  1],\n",
       "        [53,  1,  1],\n",
       "        [11,  1,  1],\n",
       "        [ 3,  1,  1]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function returns `src_mask`, `tgt_mask`, `src_padding_mask`, `tgt_padding_mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]),\n",
       " tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "         [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., -inf, -inf],\n",
       "         [0., 0., 0.,  ..., 0., 0., -inf],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True],\n",
       "         [False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True]]),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_mask(src, tgt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(characters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = max(token2idx.values()) + 1  # or len(token2idx)\n",
    "TGT_VOCAB_SIZE = max(token2idx.values()) + 1  # or len(token2idx)\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 4\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting the Data\n",
    "We use `Dataset` and `DataLoader`. `Dataset` implements two methods: `__init__`, `__len__` and `__getitem__`. The last method returns an item of the dataset given an index. Using `collate_fn`, `DataLoader` returns a batch of `batch_size` samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, input_texts, target_texts, token2idx):\n",
    "        self.input_texts = input_texts\n",
    "        self.target_texts = target_texts\n",
    "        self.token2idx = token2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_batch = text2codes([input_texts[idx]], self.token2idx)\n",
    "        tgt_batch = text2codes([target_texts[idx]], self.token2idx)\n",
    "\n",
    "        return src_batch[0], tgt_batch[0]\n",
    "\n",
    "    def collate(self, batch):\n",
    "        src_batch, tgt_batch = list(zip(*batch))\n",
    "        src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "        tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "\n",
    "        return src_batch, tgt_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairDataset(train_input_texts, train_target_texts, token2idx)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32,\n",
    "                              shuffle=True, collate_fn=train_dataset.collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = PairDataset(val_input_texts, val_target_texts, token2idx)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=32, collate_fn=val_dataset.collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    sent_cnt = 0\n",
    "    correct, total = 0, 0\n",
    "    for src_batch, tgt_batch in tqdm(dataloader):\n",
    "        src = src_batch.to(DEVICE)\n",
    "        tgt = tgt_batch.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "            src, tgt_input)\n",
    "\n",
    "        logits = model(src,\n",
    "                       tgt_input,\n",
    "                       src_mask,\n",
    "                       tgt_mask,\n",
    "                       src_padding_mask,\n",
    "                       tgt_padding_mask,\n",
    "                       src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(\n",
    "            logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sent_cnt += tgt_out.size()[-1]\n",
    "\n",
    "            total += torch.numel(tgt_input)\n",
    "            _, char_pred = torch.max(logits, -1)\n",
    "            correct += (char_pred == tgt_out).sum().item()\n",
    "\n",
    "    return losses / sent_cnt, correct / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the loss. Overall, it should computed by individual prediction and divided by the number of chars. By default the crossentropy loss uses the mean. Then we use the mean of the mean. The trend is correct, but the values are not exact. A possible improvement would be to sum and pass through the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    sent_cnt = 0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for src_batch, tgt_batch in dataloader:\n",
    "        src = src_batch.to(DEVICE)\n",
    "        tgt = tgt_batch.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "            src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,\n",
    "                       src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(\n",
    "            logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "        sent_cnt += tgt_out.size()[-1]\n",
    "\n",
    "        total += torch.numel(tgt_input)\n",
    "        _, char_pred = torch.max(logits, -1)\n",
    "        correct += (char_pred == tgt_out).sum().item()\n",
    "\n",
    "    return losses / sent_cnt, correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 31/770 [14:35<5:48:02, 28.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Git-Repos\\Language-Technology\\labs_2023\\Lab_6\\6-translation_transformer_distinct_embs.ipynb Cell 82\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, NUM_EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     start_time \u001b[39m=\u001b[39m timer()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train_epoch(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         transformer, optimizer, train_dataloader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     train_losses \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [train_loss]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     train_accs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [train_acc]\n",
      "\u001b[1;32mc:\\Git-Repos\\Language-Technology\\labs_2023\\Lab_6\\6-translation_transformer_distinct_embs.ipynb Cell 82\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m tgt_input \u001b[39m=\u001b[39m tgt[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m src_mask, tgt_mask, src_padding_mask, tgt_padding_mask \u001b[39m=\u001b[39m create_mask(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     src, tgt_input)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m logits \u001b[39m=\u001b[39m model(src,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                tgt_input,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                src_mask,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                tgt_mask,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                src_padding_mask,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                tgt_padding_mask,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                src_padding_mask)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m tgt_out \u001b[39m=\u001b[39m tgt[\u001b[39m1\u001b[39m:, :]\n",
      "File \u001b[1;32mc:\\Users\\theo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Git-Repos\\Language-Technology\\labs_2023\\Lab_6\\6-translation_transformer_distinct_embs.ipynb Cell 82\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m src_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_encoding(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_tok_emb(src))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m tgt_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_encoding(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtgt_tok_emb(trg))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m outs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer(src_emb, tgt_emb, src_mask, tgt_mask, \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m                         src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git-Repos/Language-Technology/labs_2023/Lab_6/6-translation_transformer_distinct_embs.ipynb#Y144sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator(outs)\n",
      "File \u001b[1;32mc:\\Users\\theo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\theo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:146\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m memory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(src, mask\u001b[39m=\u001b[39msrc_mask, src_key_padding_mask\u001b[39m=\u001b[39msrc_key_padding_mask)\n\u001b[1;32m--> 146\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(tgt, memory, tgt_mask\u001b[39m=\u001b[39mtgt_mask, memory_mask\u001b[39m=\u001b[39mmemory_mask,\n\u001b[0;32m    147\u001b[0m                       tgt_key_padding_mask\u001b[39m=\u001b[39mtgt_key_padding_mask,\n\u001b[0;32m    148\u001b[0m                       memory_key_padding_mask\u001b[39m=\u001b[39mmemory_key_padding_mask)\n\u001b[0;32m    149\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\theo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\theo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:369\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    366\u001b[0m output \u001b[39m=\u001b[39m tgt\n\u001b[0;32m    368\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 369\u001b[0m     output \u001b[39m=\u001b[39m mod(output, memory, tgt_mask\u001b[39m=\u001b[39mtgt_mask,\n\u001b[0;32m    370\u001b[0m                  memory_mask\u001b[39m=\u001b[39mmemory_mask,\n\u001b[0;32m    371\u001b[0m                  tgt_key_padding_mask\u001b[39m=\u001b[39mtgt_key_padding_mask,\n\u001b[0;32m    372\u001b[0m                  memory_key_padding_mask\u001b[39m=\u001b[39mmemory_key_padding_mask)\n\u001b[0;32m    374\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32mc:\\Users\\theo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\theo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:717\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))\n\u001b[1;32m--> 717\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mha_block(x, memory, memory_mask, memory_key_padding_mask, memory_is_causal))\n\u001b[0;32m    718\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[0;32m    720\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\theo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:735\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._mha_block\u001b[1;34m(self, x, mem, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mha_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, mem: Tensor,\n\u001b[0;32m    734\u001b[0m                attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 735\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultihead_attn(x, mem, mem,\n\u001b[0;32m    736\u001b[0m                             attn_mask\u001b[39m=\u001b[39mattn_mask,\n\u001b[0;32m    737\u001b[0m                             key_padding_mask\u001b[39m=\u001b[39mkey_padding_mask,\n\u001b[0;32m    738\u001b[0m                             is_causal\u001b[39m=\u001b[39mis_causal,\n\u001b[0;32m    739\u001b[0m                             need_weights\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    740\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32mc:\\Users\\theo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\theo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1205\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1192\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[0;32m   1193\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1203\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[0;32m   1204\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1205\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1206\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[0;32m   1207\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   1208\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_k, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_v, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_zero_attn,\n\u001b[0;32m   1209\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_proj\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_proj\u001b[39m.\u001b[39mbias,\n\u001b[0;32m   1210\u001b[0m         training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining,\n\u001b[0;32m   1211\u001b[0m         key_padding_mask\u001b[39m=\u001b[39mkey_padding_mask,\n\u001b[0;32m   1212\u001b[0m         need_weights\u001b[39m=\u001b[39mneed_weights,\n\u001b[0;32m   1213\u001b[0m         attn_mask\u001b[39m=\u001b[39mattn_mask,\n\u001b[0;32m   1214\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1215\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[0;32m   1216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[0;32m   1217\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\theo\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:5376\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5373\u001b[0m attn_output \u001b[39m=\u001b[39m scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n\u001b[0;32m   5374\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m-> 5376\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n\u001b[0;32m   5377\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mview(tgt_len, bsz, attn_output\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\n\u001b[0;32m   5378\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_batched:\n\u001b[0;32m   5379\u001b[0m     \u001b[39m# squeeze the output if input was unbatched\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 15\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    start_time = timer()\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        transformer, optimizer, train_dataloader)\n",
    "    train_losses += [train_loss]\n",
    "    train_accs += [train_acc]\n",
    "    end_time = timer()\n",
    "    val_loss, val_acc = evaluate(transformer, val_dataloader)\n",
    "    val_losses += [val_loss]\n",
    "    val_accs += [val_acc]\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Train acc.: {train_acc:.3f}, Val acc.: {val_acc:.3f}, Epoch time = {(end_time - start_time):.3f}s\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(NUM_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, train_losses, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_losses, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, train_accs, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_accs, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    # print(ys)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        # print(ys) # Remove the comment to understand the loop\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2],\n",
       "        [32],\n",
       "        [66],\n",
       "        [ 5],\n",
       "        [ 3]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2codes(['Go!'], token2idx)[0].view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text2codes([src_sentence], token2idx)[0].view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 20, start_symbol=BOS_IDX).flatten()\n",
    "    tgt_chars_specials = codes2text([tgt_tokens], idx2token)[0]\n",
    "    tgt_chars = []\n",
    "    for char in tgt_chars_specials:\n",
    "        if char != '<bos>' and char != '<eos>':\n",
    "            tgt_chars += [char]\n",
    "    tgt_chars = ''.join(tgt_chars)\n",
    "    return tgt_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Viendras-tu à la maison ?'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_sent = translate(transformer, 'Will you come home?')\n",
    "tgt_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Monte aux remportes jamais à l'énerve.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_sent = translate(\n",
    "    transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\")\n",
    "tgt_sent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(transformer, 'simple_params_v3.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "In your report, you will first summarize the paper _Attention Is All You Need_ (https://arxiv.org/abs/1706.03762) in about half a page. You will then describe the encoder-decoder architecture in the notebook. \n",
    "\n",
    "Please follow the outline below and use the same section names as those in bold:\n",
    "- __Dataset__: Describe your dataset;\n",
    "- __Encoder-Decoder__: Describe the overall architecture;\n",
    "- __Embeddings__: Explain the embeddings, positional encodings and character embeddings\n",
    "- __Self-Attention__: Explain self-attention\n",
    "- __Decoder__: Describe the decoder\n",
    "- __Inference__: Describe the inference\n",
    "- __Experiments and Results__: Describe and comment your experiments and results. You should try at least two sets of parameters (e.g. number of heads, number of layers, number of epochs, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
